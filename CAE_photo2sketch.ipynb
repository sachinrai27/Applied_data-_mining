{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Auto encoder\n",
        "# Importing reuiqred libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import MeanSquaredError\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Defining directories for images and sketches\n",
        "img_dir = 'cuhk_training'\n",
        "sketch_dir = 'cuhk_train_sketch'\n",
        "\n",
        "\n",
        "img_rows, img_cols = 256, 256\n"
      ],
      "metadata": {
        "id": "FqfgW0h8YVe5"
      },
      "id": "FqfgW0h8YVe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "# Load and preprocess images and sketches\n",
        "# Sorting the images\n",
        "img_list = sorted(os.listdir(img_dir))\n",
        "sketch_list = sorted(os.listdir(sketch_dir))\n",
        "img_list.sort()\n",
        "sketch_list.sort()\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "# Looping over to get the images and sketches\n",
        "for i in range(num_imgs):\n",
        "  img_path = os.path.join(img_dir, img_list[i])\n",
        "  sketch_path = os.path.join(sketch_dir, sketch_list[i])\n",
        "\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "  img = cv2.resize(img, (img_rows, img_cols))\n",
        "  # Preprocessing: Apply Gaussian blur to input images to remove noise\n",
        "  img = cv2.GaussianBlur(img, (5,5), 0)\n",
        "\n",
        "  sketch = cv2.imread(sketch_path, cv2.IMREAD_GRAYSCALE)\n",
        "  sketch = cv2.resize(sketch, (img_rows, img_cols))\n",
        "\n",
        "  X_train.append(img)\n",
        "  Y_train.append(sketch)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "# Reshape and normalize images\n",
        "X_train = X_train.reshape(-1, img_rows, img_cols, 1) / 255.0\n",
        "Y_train = Y_train.reshape(-1, img_rows, img_cols, 1) / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "aZUnXBykajXR"
      },
      "id": "aZUnXBykajXR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define convolutional autoencoder architecture\n",
        "input_img = Input(shape=(img_rows, img_cols, 1))\n",
        "\n",
        "# Encoder\n",
        "input_img = Input(shape=(img_rows, img_cols, 1))\n",
        "# Encoder\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# Hidden layer 2\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# Hidden layer 3\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# Hidden layer 4\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# Hidden layer 6\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# Hidden layer 7\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "# Autoencoder\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Learning rate\n",
        "autoencoder.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=[MeanSquaredError()])\n",
        "\n"
      ],
      "metadata": {
        "id": "hHmqcEA9ZIri"
      },
      "id": "hHmqcEA9ZIri",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "hist = autoencoder.fit(X_train, Y_train, epochs=100, batch_size=16, shuffle=True, validation_split=0.2)\n",
        "\n",
        "# Plot the reconstruction loss over epochs\n",
        "plt.plot(hist.history[\"loss\"])\n",
        "plt.plot(hist.history[\"val_loss\"])\n",
        "plt.legend([\"Training loss\"],[\"Validaton loss\"])\n",
        "plt.title(\"Reconstruction Loss over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lMttiGTnao-H"
      },
      "id": "lMttiGTnao-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sketches for new images\n",
        "data_dir = '/content/drive/MyDrive/'\n",
        "new_images_dir = os.path.join(data_dir, 'cuhk_test_photos')\n",
        "\n",
        "output_dir = os.path.join(data_dir, 'cuhk_ae_out')\n",
        "# output_dir = os.path.join(data_dir, 'cae_feret_trained_cuhk_out')\n",
        "\n",
        "# Load test dataset\n",
        "X_test = []\n",
        "\n",
        "for img_file in os.listdir(new_images_dir):\n",
        "    img_path = os.path.join(new_images_dir, img_file)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (256, 256))  # resize image\n",
        "    X_test.append(img)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Reshape and normalize images\n",
        "X_test = X_test.reshape(-1, 256, 256, 1) / 255.0\n",
        "\n",
        "# Generate and save sketches\n",
        "for i in range(len(X_test)):\n",
        "    sketch = autoencoder.predict(X_test[i].reshape(1, 256, 256, 1))\n",
        "    sketch = sketch.reshape(256, 256) * 255.0\n",
        "    sketch_path = os.path.join(output_dir, 'sketch_' + str(i) + '.jpg')\n",
        "    cv2.imwrite(sketch_path, sketch)\n",
        "    "
      ],
      "metadata": {
        "id": "lsYKWvwQa9FX"
      },
      "id": "lsYKWvwQa9FX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "Y_test = []\n",
        "# Sorting the images\n",
        "sketch_dirr = '/content/drive/MyDrive/cuhk_ae_test_out'\n",
        "sketch_test = sorted(os.listdir(sketch_dirr))\n",
        "sketch_test.sort()\n",
        "num_imgs = len(img_list)\n",
        "\n",
        "# Looping over to get the images and sketches\n",
        "for i in range(100):\n",
        "  sketch_path = os.path.join(sketch_dir, sketch_list[i])\n",
        "  sketch = cv2.imread(sketch_path, cv2.IMREAD_GRAYSCALE)\n",
        "  sketch = cv2.resize(sketch, (img_rows, img_cols))\n",
        "  Y_test.append(sketch)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "# Reshape and normalize images\n",
        "Y_test = Y_test.reshape(-1, img_rows, img_cols, 1) / 255.0\n",
        "\n",
        "# Predict on the test set\n",
        "Y_pred = autoencoder.predict(X_test)\n",
        "\n",
        "# Calculating MSE\n",
        "mse = np.mean((Y_test - Y_pred) ** 2)\n",
        "\n",
        "# Plotting the MSE\n",
        "plt.plot(hist.history['mean_squared_error'])\n",
        "plt.plot(hist.history['val_mean_squared_error'])\n",
        "plt.title('Mean Squared Error')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AMIsYxNZVEjA"
      },
      "id": "AMIsYxNZVEjA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}